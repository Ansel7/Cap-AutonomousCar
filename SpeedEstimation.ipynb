{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "440b81bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (20400, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 20399/20399 [00:32<00:00, 622.82it/s]\n",
      "/Users/abrahambojorquez/opt/opencv-env/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "/var/folders/lt/d9bjr74x5h15ntcpnld18xv40000gn/T/ipykernel_42119/918806554.py:370: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "valid_data:  (9032, 4)\n",
      "train_data:  (31766, 4)\n",
      "val_size:  9032\n",
      "Epoch 1/20\n",
      "400/400 [==============================] - ETA: 0s - loss: 83.5628\n",
      "Epoch 1: val_loss improved from inf to 44.69889, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 266s 665ms/step - loss: 83.5628 - val_loss: 44.6989\n",
      "Epoch 2/20\n",
      "400/400 [==============================] - ETA: 0s - loss: 44.8583\n",
      "Epoch 2: val_loss improved from 44.69889 to 37.59932, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 250s 627ms/step - loss: 44.8583 - val_loss: 37.5993\n",
      "Epoch 3/20\n",
      "400/400 [==============================] - ETA: 0s - loss: 36.4354\n",
      "Epoch 3: val_loss improved from 37.59932 to 29.62090, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 252s 632ms/step - loss: 36.4354 - val_loss: 29.6209\n",
      "Epoch 4/20\n",
      "400/400 [==============================] - ETA: 0s - loss: 30.2801\n",
      "Epoch 4: val_loss improved from 29.62090 to 23.34155, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 266s 667ms/step - loss: 30.2801 - val_loss: 23.3416\n",
      "Epoch 5/20\n",
      "400/400 [==============================] - ETA: 0s - loss: 25.9896\n",
      "Epoch 5: val_loss improved from 23.34155 to 18.59338, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 265s 664ms/step - loss: 25.9896 - val_loss: 18.5934\n",
      "Epoch 6/20\n",
      "400/400 [==============================] - ETA: 0s - loss: 22.5968\n",
      "Epoch 6: val_loss improved from 18.59338 to 18.04561, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 261s 654ms/step - loss: 22.5968 - val_loss: 18.0456\n",
      "Epoch 7/20\n",
      "400/400 [==============================] - ETA: 0s - loss: 18.8640\n",
      "Epoch 7: val_loss improved from 18.04561 to 15.99460, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 261s 655ms/step - loss: 18.8640 - val_loss: 15.9946\n",
      "Epoch 8/20\n",
      "400/400 [==============================] - ETA: 0s - loss: 18.2240\n",
      "Epoch 8: val_loss improved from 15.99460 to 15.83349, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 260s 652ms/step - loss: 18.2240 - val_loss: 15.8335\n",
      "Epoch 9/20\n",
      "400/400 [==============================] - ETA: 0s - loss: 16.1635\n",
      "Epoch 9: val_loss improved from 15.83349 to 14.24703, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 261s 653ms/step - loss: 16.1635 - val_loss: 14.2470\n",
      "Epoch 10/20\n",
      "400/400 [==============================] - ETA: 0s - loss: 15.2412\n",
      "Epoch 10: val_loss improved from 14.24703 to 10.62363, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 246s 617ms/step - loss: 15.2412 - val_loss: 10.6236\n",
      "Epoch 11/20\n",
      "400/400 [==============================] - ETA: 0s - loss: 14.2115\n",
      "Epoch 11: val_loss improved from 10.62363 to 10.18870, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 255s 640ms/step - loss: 14.2115 - val_loss: 10.1887\n",
      "Epoch 12/20\n",
      "400/400 [==============================] - ETA: 0s - loss: 12.6342\n",
      "Epoch 12: val_loss did not improve from 10.18870\n",
      "400/400 [==============================] - 245s 613ms/step - loss: 12.6342 - val_loss: 10.4511\n",
      "Epoch 13/20\n",
      "400/400 [==============================] - ETA: 0s - loss: 11.4254\n",
      "Epoch 13: val_loss did not improve from 10.18870\n",
      "400/400 [==============================] - 245s 615ms/step - loss: 11.4254 - val_loss: 10.3404\n",
      "Epoch 14/20\n",
      "400/400 [==============================] - ETA: 0s - loss: 11.2823\n",
      "Epoch 14: val_loss improved from 10.18870 to 9.52688, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 251s 628ms/step - loss: 11.2823 - val_loss: 9.5269\n",
      "Epoch 15/20\n",
      "400/400 [==============================] - ETA: 0s - loss: 10.1699\n",
      "Epoch 15: val_loss improved from 9.52688 to 8.23084, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 251s 628ms/step - loss: 10.1699 - val_loss: 8.2308\n",
      "Epoch 16/20\n",
      "400/400 [==============================] - ETA: 0s - loss: 9.5581\n",
      "Epoch 16: val_loss did not improve from 8.23084\n",
      "400/400 [==============================] - 245s 614ms/step - loss: 9.5581 - val_loss: 8.6749\n",
      "Epoch 17/20\n",
      "400/400 [==============================] - ETA: 0s - loss: 9.3646\n",
      "Epoch 17: val_loss improved from 8.23084 to 7.89191, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 245s 613ms/step - loss: 9.3646 - val_loss: 7.8919\n",
      "Epoch 18/20\n",
      "400/400 [==============================] - ETA: 0s - loss: 8.2748\n",
      "Epoch 18: val_loss did not improve from 7.89191\n",
      "400/400 [==============================] - 245s 613ms/step - loss: 8.2748 - val_loss: 8.4313\n",
      "Epoch 19/20\n",
      "400/400 [==============================] - ETA: 0s - loss: 7.9615\n",
      "Epoch 19: val_loss did not improve from 7.89191\n",
      "400/400 [==============================] - 245s 613ms/step - loss: 7.9615 - val_loss: 8.7733\n",
      "Epoch 20/20\n",
      "400/400 [==============================] - ETA: 0s - loss: 7.6168\n",
      "Epoch 20: val_loss improved from 7.89191 to 5.76939, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 245s 614ms/step - loss: 7.6168 - val_loss: 5.7694\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#most of the code is from https://github.com/jovsa/speed-challenge-2017\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import h5py\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.core import Activation, Dropout, Flatten, Dense, Lambda\n",
    "from keras.layers import ELU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as KTF\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# constants\n",
    "TRAIN_VIDEO = 'train.mp4'\n",
    "TEST_VIDEO = 'test.mp4'\n",
    "CLEAN_IMGS_TRAIN = 'CLEAN_IMGS_TRAIN/'\n",
    "CLEAN_IMGS_TEST = 'CLEAN_IMGS_TEST/'\n",
    "\n",
    "train_frames = 20400\n",
    "test_frames = 10798\n",
    "\n",
    "seeds = [1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144]\n",
    "\n",
    "\n",
    "train_meta = pd.read_csv('train_meta.csv')\n",
    "print('shape: ', train_meta.shape)\n",
    "\n",
    "\n",
    "# note: there is a chance that points might appear again. as n\n",
    "\n",
    "def train_valid_split(dframe, seed_val):\n",
    "    \"\"\"\n",
    "    Randomly shuffle pairs of rows in the dataframe, separates train and validation data\n",
    "    generates a uniform random variable 0->9, gives 20% chance to append to valid data, otherwise train_data\n",
    "    return tuple (train_data, valid_data) dataframes\n",
    "    \"\"\"\n",
    "    train_data = pd.DataFrame()\n",
    "    valid_data = pd.DataFrame()\n",
    "    np.random.seed(seed_val)\n",
    "    for i in tqdm(range(len(dframe) - 1)):\n",
    "        idx1 = np.random.randint(len(dframe) - 1)\n",
    "        idx2 = idx1 + 1\n",
    "        \n",
    "        \n",
    "        row1 = dframe.iloc[[idx1]].reset_index()\n",
    "        row2 = dframe.iloc[[idx2]].reset_index()\n",
    "        \n",
    "        randInt = np.random.randint(9)\n",
    "        if 0 <= randInt <= 1:\n",
    "            valid_frames = [valid_data, row1, row2]\n",
    "            valid_data = pd.concat(valid_frames, axis = 0, join = 'outer', ignore_index=False)\n",
    "        if randInt >= 2:\n",
    "            train_frames = [train_data, row1, row2]\n",
    "            train_data = pd.concat(train_frames, axis = 0, join = 'outer', ignore_index=False)\n",
    "    return train_data, valid_data\n",
    "\n",
    "\n",
    "train_data, valid_data = train_valid_split(train_meta, seeds[0])\n",
    "\n",
    "#ignored because of time constraints\n",
    "\"\"\"fig, ax = plt.subplots(figsize=(20,10))\n",
    "plt.plot(train_data.sort_values(['image_index'])[['image_index']], train_data.sort_values(['image_index'])[['speed']], 'ro')\n",
    "plt.plot(valid_data.sort_values(['image_index'])[['image_index']], valid_data.sort_values(['image_index'])[['speed']], 'go')\n",
    "plt.xlabel('image_index (or time since start)')\n",
    "plt.ylabel('speed')\n",
    "plt.title('Speed vs time')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.savefig('./assets/speed_vs_time_val_train.png')\n",
    "plt.close()\n",
    "\"\"\"\n",
    "print('----')\n",
    "print('valid_data: ', valid_data.shape)\n",
    "print('train_data: ', train_data.shape)\n",
    "\n",
    "def change_brightness(image, bright_factor):\n",
    "    \"\"\"\n",
    "    Augments the brightness of the image by multiplying the saturation by a uniform random variable\n",
    "    Input: image (RGB)\n",
    "    returns: image with brightness augmentation\n",
    "    \"\"\"\n",
    "    \n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    # perform brightness augmentation only on the second channel\n",
    "    hsv_image[:,:,2] = hsv_image[:,:,2] * bright_factor\n",
    "    \n",
    "    # change back to RGB\n",
    "    image_rgb = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2RGB)\n",
    "    return image_rgb\n",
    "\n",
    "\n",
    "def opticalFlowDense(image_current, image_next):\n",
    "    \"\"\"\n",
    "    input: image_current, image_next (RGB images)\n",
    "    calculates optical flow magnitude and angle and places it into HSV image\n",
    "    * Set the saturation to the saturation value of image_next\n",
    "    * Set the hue to the angles returned from computing the flow params\n",
    "    * set the value to the magnitude returned from computing the flow params\n",
    "    * Convert from HSV to RGB and return RGB image with same size as original image\n",
    "    \"\"\"\n",
    "    gray_current = cv2.cvtColor(image_current, cv2.COLOR_RGB2GRAY)\n",
    "    gray_next = cv2.cvtColor(image_next, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    \n",
    "    hsv = np.zeros((66, 220, 3))\n",
    "    # set saturation\n",
    "    hsv[:,:,1] = cv2.cvtColor(image_next, cv2.COLOR_RGB2HSV)[:,:,1]\n",
    " \n",
    "    # Flow Parameters\n",
    "    # flow_mat = cv2.CV_32FC2\n",
    "    flow_mat = None\n",
    "    image_scale = 0.5\n",
    "    nb_images = 1\n",
    "    win_size = 15\n",
    "    nb_iterations = 2\n",
    "    deg_expansion = 5\n",
    "    STD = 1.3\n",
    "    extra = 0\n",
    "\n",
    "    # obtain dense optical flow paramters\n",
    "    flow = cv2.calcOpticalFlowFarneback(gray_current, gray_next,  \n",
    "                                        flow_mat, \n",
    "                                        image_scale, \n",
    "                                        nb_images, \n",
    "                                        win_size, \n",
    "                                        nb_iterations, \n",
    "                                        deg_expansion, \n",
    "                                        STD, \n",
    "                                        0)\n",
    "                                        \n",
    "        \n",
    "    # convert from cartesian to polar\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])  \n",
    "        \n",
    "    # hue corresponds to direction\n",
    "    hsv[:,:,0] = ang * (180/ np.pi / 2)\n",
    "    \n",
    "    # value corresponds to magnitude\n",
    "    hsv[:,:,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    \n",
    "    # convert HSV to float32's\n",
    "    hsv = np.asarray(hsv, dtype= np.float32)\n",
    "    rgb_flow = cv2.cvtColor(hsv,cv2.COLOR_HSV2RGB)\n",
    "\n",
    "    \n",
    "    return rgb_flow\n",
    "\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    preprocesses the image\n",
    "    \n",
    "    input: image (480 (y), 640 (x), 3) RGB\n",
    "    output: image (shape is (220, 66, 3) as RGB)\n",
    "    \n",
    "    This stuff is performed on my validation data and my training data\n",
    "    Process: \n",
    "             1) Cropping out black spots\n",
    "             3) resize to (220, 66, 3) if not done so already from perspective transform\n",
    "    \"\"\"\n",
    "    # Crop out sky (top) (100px) and black right part (-90px)\n",
    "    image_cropped = image[100:440, :-90] # -> (380, 550, 3)\n",
    "    \n",
    "    image = cv2.resize(image_cropped, (220, 66), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def preprocess_image_valid_from_path(image_path, speed):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = preprocess_image(img)\n",
    "    return img, speed\n",
    "\n",
    "def preprocess_image_from_path(image_path, speed, bright_factor):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return img, 0\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = change_brightness(img, bright_factor)    \n",
    "    img = preprocess_image(img)\n",
    "    return img, speed\n",
    "\n",
    "def generate_training_data(data, batch_size = 32):\n",
    "    image_batch = np.zeros((batch_size, 66, 220, 3)) # nvidia input params\n",
    "    label_batch = np.zeros((batch_size))\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            # generate a random index with a uniform random distribution from 1 to len - 1\n",
    "            idx = np.random.randint(1, len(data) - 1)\n",
    "            \n",
    "            # Generate a random bright factor to apply to both images\n",
    "            bright_factor = 0.2 + np.random.uniform()\n",
    "            \n",
    "            row_now = data.iloc[[idx]].reset_index()\n",
    "            row_prev = data.iloc[[idx - 1]].reset_index()\n",
    "            row_next = data.iloc[[idx + 1]].reset_index()\n",
    "            \n",
    "            # Find the 3 respective times to determine frame order (current -> next)\n",
    "            \n",
    "            time_now = row_now['image_index'].values[0]\n",
    "            time_prev = row_prev['image_index'].values[0]\n",
    "            time_next = row_next['image_index'].values[0]\n",
    "            \n",
    "            if abs(time_now - time_prev) == 1 and time_now > time_prev:\n",
    "                row1 = row_prev\n",
    "                row2 = row_now\n",
    "                \n",
    "            elif abs(time_next - time_now) == 1 and time_next > time_now:\n",
    "                row1 = row_now\n",
    "                row2 = row_next\n",
    "            else:\n",
    "                print('Error generating row')            \n",
    "            \n",
    "            x1, y1 = preprocess_image_from_path(row1['image_path'].values[0],\n",
    "                                                row1['speed'].values[0],\n",
    "                                               bright_factor)\n",
    "            \n",
    "            # preprocess another image\n",
    "            x2, y2 = preprocess_image_from_path(row2['image_path'].values[0], \n",
    "                                                row2['speed'].values[0],\n",
    "                                               bright_factor)\n",
    "           \n",
    "            # compute optical flow send in images as RGB\n",
    "            rgb_diff = opticalFlowDense(x1, x2)\n",
    "                        \n",
    "            # calculate mean speed\n",
    "            y = np.mean([y1, y2])\n",
    "            \n",
    "            image_batch[i] = rgb_diff\n",
    "            label_batch[i] = y\n",
    "        \n",
    "        #print('image_batch', image_batch.shape, ' label_batch', label_batch)\n",
    "        # Shuffle the pairs before they get fed into the network\n",
    "        yield shuffle(image_batch, label_batch)\n",
    "\n",
    "def generate_validation_data(data):\n",
    "    while True:\n",
    "        for idx in range(1, len(data) - 1): # start from the second row because we may try to grab it and need its prev to be in bounds\n",
    "            row_now = data.iloc[[idx]].reset_index()\n",
    "            row_prev = data.iloc[[idx - 1]].reset_index()\n",
    "            row_next = data.iloc[[idx + 1]].reset_index()\n",
    "            \n",
    "            # Find the 3 respective times to determine frame order (current -> next)\n",
    "            \n",
    "            time_now = row_now['image_index'].values[0]\n",
    "            time_prev = row_prev['image_index'].values[0]\n",
    "            time_next = row_next['image_index'].values[0]\n",
    "            \n",
    "            if abs(time_now - time_prev) == 1 and time_now > time_prev:\n",
    "                row1 = row_prev\n",
    "                row2 = row_now\n",
    "                \n",
    "            elif abs(time_next - time_now) == 1 and time_next > time_now:\n",
    "                row1 = row_now\n",
    "                row2 = row_next\n",
    "            else:\n",
    "                print('Error generating row')        \n",
    "            \n",
    "            x1, y1 = preprocess_image_valid_from_path(row1['image_path'].values[0], row1['speed'].values[0])\n",
    "            x2, y2 = preprocess_image_valid_from_path(row2['image_path'].values[0], row2['speed'].values[0])\n",
    "            \n",
    "            img_diff = opticalFlowDense(x1, x2)\n",
    "            img_diff = img_diff.reshape(1, img_diff.shape[0], img_diff.shape[1], img_diff.shape[2])\n",
    "            y = np.mean([y1, y2])\n",
    "            \n",
    "            speed = np.array([[y]])\n",
    "            \n",
    "            #print('img_diff', img_diff.shape, ' speed', speed)\n",
    "            yield img_diff, speed\n",
    "\n",
    "\n",
    "N_img_height = 66\n",
    "N_img_width = 220\n",
    "N_img_channels = 3\n",
    "def nvidia_model():\n",
    "    inputShape = (N_img_height, N_img_width, N_img_channels)\n",
    "\n",
    "    model = Sequential()\n",
    "    # normalization    \n",
    "    # perform custom normalization before lambda layer in network\n",
    "    model.add(Lambda(lambda x: x/ 127.5 - 1, input_shape = inputShape))\n",
    "\n",
    "    model.add(Convolution2D(24, (5, 5), \n",
    "                            strides=(2,2), \n",
    "                            padding = 'valid',\n",
    "                            kernel_initializer = 'he_normal',\n",
    "                            name = 'conv1'))\n",
    "    \n",
    "    \n",
    "    model.add(ELU())    \n",
    "    model.add(Convolution2D(36, (5, 5), \n",
    "                            strides=(2,2), \n",
    "                            padding = 'valid',\n",
    "                            kernel_initializer = 'he_normal',\n",
    "                            name = 'conv2'))\n",
    "    \n",
    "    model.add(ELU())    \n",
    "    model.add(Convolution2D(48, (5, 5), \n",
    "                            strides=(2,2), \n",
    "                            padding = 'valid',\n",
    "                            kernel_initializer = 'he_normal',\n",
    "                            name = 'conv3'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(64, (3, 3), \n",
    "                            strides = (1,1), \n",
    "                            padding = 'valid',\n",
    "                            kernel_initializer = 'he_normal',\n",
    "                            name = 'conv4'))\n",
    "    \n",
    "    model.add(ELU())              \n",
    "    model.add(Convolution2D(64, (3, 3), \n",
    "                            strides= (1,1), \n",
    "                            padding = 'valid',\n",
    "                            kernel_initializer = 'he_normal',\n",
    "                            name = 'conv5'))\n",
    "              \n",
    "              \n",
    "    model.add(Flatten(name = 'flatten'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(100, kernel_initializer = 'he_normal', name = 'fc1'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(50, kernel_initializer = 'he_normal', name = 'fc2'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(10, kernel_initializer = 'he_normal', name = 'fc3'))\n",
    "    model.add(ELU())\n",
    "    \n",
    "    # do not put activation at the end because we want to exact output, not a class identifier\n",
    "    model.add(Dense(1, name = 'output', kernel_initializer = 'he_normal'))\n",
    "    \n",
    "    adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(optimizer = adam, loss = 'mse')\n",
    "\n",
    "    return model\n",
    "\n",
    "val_size = len(valid_data.index)\n",
    "valid_generator = generate_validation_data(valid_data)\n",
    "BATCH = 16\n",
    "print('val_size: ', val_size)\n",
    "\n",
    "filepath = 'model-weights-Vtest3.h5'\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', \n",
    "                              patience=1, \n",
    "                              verbose=1, \n",
    "                              min_delta = 0.23,\n",
    "                              mode='min',)\n",
    "modelCheckpoint = ModelCheckpoint(filepath, \n",
    "                                  monitor = 'val_loss', \n",
    "                                  save_best_only = True, \n",
    "                                  mode = 'min', \n",
    "                                  verbose = 1,\n",
    "                                 save_weights_only = True)\n",
    "callbacks_list = [modelCheckpoint]\n",
    "\n",
    "\n",
    "model = nvidia_model()\n",
    "train_size = len(train_data.index)\n",
    "train_generator = generate_training_data(train_data, BATCH)\n",
    "history = model.fit_generator(\n",
    "        train_generator, \n",
    "        steps_per_epoch = 400, \n",
    "        epochs = 16,\n",
    "        callbacks = callbacks_list,\n",
    "        verbose = 1,\n",
    "        validation_data = valid_generator,\n",
    "        validation_steps = val_size)\n",
    "\n",
    "#print(history)\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "plt.plot(history.history['loss'], 'ro--')\n",
    "plt.plot(history.history['val_loss'], 'go--')\n",
    "plt.title('Model-v2test mean squared error loss 15 epochs')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.savefig('MSE_per_epoch.png')\n",
    "plt.close()\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd157e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv-env",
   "language": "python",
   "name": "opencv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
